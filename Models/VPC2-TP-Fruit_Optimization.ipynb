{"cells":[{"cell_type":"markdown","metadata":{"id":"SCL9lVaCMoOD"},"source":["# Trabajo Práctico - CEIA Vision por Computadora II\n","\n","Alumno: Alianak, Juan Pablo\n","\n","En este trabajo analizaremos el dataset Fruit. El dataset cuenta 3155 imagenes de 11 clases diferentes de frutas. \n","\n","El objetivo final será modelar un clasificador con redes convolucionales que sea capaz de, dada una imagen dentro de estas clases, predecir a cual de ellas pertenece.\n","\n","Las noteboos estan divididas en 3 partes:\n","\n","- VCP2-TP-Fruit\n","\n","  En esta notebook implementaremos distintos modelos con y sin Data Aumentation para observar el comportamiento de cada uno de ellos.\n","\n","- VCP2-TP-Fruit-Transfer_learning\n","\n","  En esta notebook, con el modelo elegido en base al punto anterior, impplementaremos transfer lerning y evaluaremos resultados.\n","\n","- VCP2-TP-Fruit-Optimization\n","\n","  En esta notebook haremos optimizacion de algunos hiperparametros tomando como modelo el generado con trasfer learning.\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8078,"status":"ok","timestamp":1665660625987,"user":{"displayName":"Juan Pablo Alianak","userId":"15176005573402506761"},"user_tz":180},"id":"IIgEkrgVx_mz","outputId":"0cd67532-c33a-4b0f-f07d-064f91a225dc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: ray[tune] in /usr/local/lib/python3.7/dist-packages (2.0.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.8.0)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (22.1.0)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (4.3.3)\n","Requirement already satisfied: aiosignal in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.2.0)\n","Requirement already satisfied: frozenlist in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.3.1)\n","Requirement already satisfied: grpcio<=1.43.0,>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.43.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (4.1.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (2.23.0)\n","Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.21.6)\n","Requirement already satisfied: protobuf<4.0.0,>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.17.3)\n","Requirement already satisfied: virtualenv in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (20.16.5)\n","Requirement already satisfied: click<=8.0.4,>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (7.1.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (6.0)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.0.4)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.3.5)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (0.8.10)\n","Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (2.5.1)\n","Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio<=1.43.0,>=1.28.1->ray[tune]) (1.15.0)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]) (5.10.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]) (5.0.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]) (0.18.1)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema->ray[tune]) (3.9.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[tune]) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[tune]) (2022.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (1.24.3)\n","Requirement already satisfied: platformdirs<3,>=2.4 in /usr/local/lib/python3.7/dist-packages (from virtualenv->ray[tune]) (2.5.2)\n","Requirement already satisfied: distlib<1,>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from virtualenv->ray[tune]) (0.3.6)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torchmetrics in /usr/local/lib/python3.7/dist-packages (0.10.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (4.1.1)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n","Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.12.1+cu113)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.9)\n"]}],"source":["!pip install ray[tune]\n","!pip install torchmetrics"]},{"cell_type":"markdown","metadata":{"id":"cIC1ztXzM4Gz"},"source":["### Importamos las librerias necesarias"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":2485,"status":"ok","timestamp":1665660631542,"user":{"displayName":"Juan Pablo Alianak","userId":"15176005573402506761"},"user_tz":180},"id":"ekDxnPBB8CvJ"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","import torchsummary\n","\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader,Dataset\n","\n","from google.colab.patches import cv2_imshow \n","import cv2\n","import pandas as pd\n","\n","import torchmetrics\n","\n","import ray\n","from ray import tune\n","from ray.air import session\n","from ray.air.checkpoint import Checkpoint\n","from ray.tune.schedulers import ASHAScheduler\n","from ray.tune import CLIReporter\n","\n","import os\n","import torch.optim as optim\n","from filelock import FileLock\n","from torch.utils.data import random_split\n","\n","from torchvision.models.inception import Inception_V3_Weights"]},{"cell_type":"markdown","metadata":{"id":"06UiQBZUM9Yv"},"source":["### Montamos el drive para acceder a los datos"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"aZlq32ojlKiE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665660639666,"user_tz":180,"elapsed":7004,"user":{"displayName":"Juan Pablo Alianak","userId":"15176005573402506761"}},"outputId":"b62cb845-ab66-48bb-e714-274a9cac0b3b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive',force_remount=True)"]},{"cell_type":"markdown","metadata":{"id":"EtXvXMeaNXxT"},"source":["### Carga de los nombres de las imagenes y de las clases"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"Lh-tT1j3_BBk","executionInfo":{"status":"ok","timestamp":1665660642255,"user_tz":180,"elapsed":537,"user":{"displayName":"Juan Pablo Alianak","userId":"15176005573402506761"}}},"outputs":[],"source":["csv_train = pd.read_csv('/content/drive/MyDrive/Colab_Notebooks/CEIA/VPC2/TP/Fruit_multiclass/train/classes.csv')\n","csv_valid = pd.read_csv('/content/drive/MyDrive/Colab_Notebooks/CEIA/VPC2/TP/Fruit_multiclass/valid/classes.csv')\n","csv_test  = pd.read_csv('/content/drive/MyDrive/Colab_Notebooks/CEIA/VPC2/TP/Fruit_multiclass/test/classes.csv')"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"Y0bHEcoUU4u0","executionInfo":{"status":"ok","timestamp":1665660647179,"user_tz":180,"elapsed":644,"user":{"displayName":"Juan Pablo Alianak","userId":"15176005573402506761"}}},"outputs":[],"source":["class ImageDataset(Dataset):\n","  def __init__(self,csv,img_folder,transform):\n","    self.csv=csv\n","    self.transform=transform\n","    self.img_folder=img_folder\n","    self.image_names=self.csv[:]['filename']\n","    #self.labels=np.array(self.csv.drop(['filename'], axis=1), dtype=float)\n","    self.class2index = {'Apple':0, 'Banana':1, 'Coconut':2, 'Dragon':3, 'Grape':4, 'Mango':5, 'Orange':6, 'Papaya':7, 'Pineapple':8, 'Star_Fruit':9, 'Strawberry':10}\n","\n","  #The __len__ function returns the number of samples in our dataset.\n","  def __len__(self):\n","    return len(self.image_names)\n"," \n","  def __getitem__(self,index):\n","     \n","    image=cv2.imread(self.img_folder+self.image_names.iloc[index])\n","    image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n"," \n","    image=self.transform(image)\n","    targets = self.class2index[self.csv.loc[index]['label']]\n","\n","    return image, targets"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"76XuJkZWDawV","executionInfo":{"status":"ok","timestamp":1665660648962,"user_tz":180,"elapsed":7,"user":{"displayName":"Juan Pablo Alianak","userId":"15176005573402506761"}}},"outputs":[],"source":["weights = Inception_V3_Weights.IMAGENET1K_V1\n","\n","transf = weights.transforms()\n","Crop_size = transf.crop_size\n","Resize_size = transf.resize_size\n","Mean = transf.mean\n","Std = transf.std"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"unm0CAGuY35q","executionInfo":{"status":"ok","timestamp":1665660649633,"user_tz":180,"elapsed":3,"user":{"displayName":"Juan Pablo Alianak","userId":"15176005573402506761"}}},"outputs":[],"source":["def load_data():\n","  data_transforms = torchvision.transforms.Compose([\n","                          transforms.ToPILImage(),\n","                          torchvision.transforms.CenterCrop(size=(Crop_size[0], Crop_size[0])),\n","                          torchvision.transforms.Resize(size=(Resize_size[0], Resize_size[0])),\n","                          torchvision.transforms.ToTensor(),\n","                          transforms.Normalize(mean=Mean, std=Std)\n","                        ])\n","\n","  train_set = ImageDataset(csv=csv_train,img_folder='/content/drive/MyDrive/Colab_Notebooks/CEIA/VPC2/TP/Fruit_multiclass/train/',transform=data_transforms)\n","  valid_set = ImageDataset(csv=csv_valid,img_folder='/content/drive/MyDrive/Colab_Notebooks/CEIA/VPC2/TP/Fruit_multiclass/valid/',transform=data_transforms)\n","  test_set  = ImageDataset(csv=csv_test,img_folder='/content/drive/MyDrive/Colab_Notebooks/CEIA/VPC2/TP/Fruit_multiclass/test/',transform=data_transforms)\n","\n","  #train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\n","  #valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=32, shuffle=True)\n","  #test_loader  = torch.utils.data.DataLoader(test_set, batch_size=32, shuffle=True)\n","\n","  return train_set, test_set"]},{"cell_type":"markdown","metadata":{"id":"yAxKnUcQN2Ah"},"source":["### Implementacion de los modelos"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"8y6asxpBDtDU","executionInfo":{"status":"ok","timestamp":1665660651619,"user_tz":180,"elapsed":7,"user":{"displayName":"Juan Pablo Alianak","userId":"15176005573402506761"}}},"outputs":[],"source":["def Net():\n","  \n","  weights = Inception_V3_Weights.IMAGENET1K_V1\n","\n","  model = torchvision.models.inception_v3(weights=weights)\n","\n","  for param in model.parameters():\n","      param.requires_grad = False\n","\n","  last_layer_in_features = model.fc.in_features\n","  model.fc = nn.Linear(last_layer_in_features, 11)\n","\n","  return model"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"nSw5Pg4Tbctx","executionInfo":{"status":"ok","timestamp":1665660653809,"user_tz":180,"elapsed":7,"user":{"displayName":"Juan Pablo Alianak","userId":"15176005573402506761"}}},"outputs":[],"source":["def train_inceptionv3(config):\n","  \n","  model = Net()\n","\n","  device = \"cpu\"\n","  if torch.cuda.is_available():\n","      device = \"cuda:0\"\n","      if torch.cuda.device_count() > 1:\n","          model = nn.DataParallel(model)\n","  model.to(device)\n","\n","  criterion = nn.CrossEntropyLoss()\n","  optimizer = torch.optim.Adam(model.parameters(), lr=config[\"lr\"])\n","\n","  # To restore a checkpoint, use `session.get_checkpoint()`.\n","  loaded_checkpoint = session.get_checkpoint()\n","  \n","  if loaded_checkpoint:\n","      with loaded_checkpoint.as_directory() as loaded_checkpoint_dir:\n","         model_state, optimizer_state = torch.load(os.path.join(loaded_checkpoint_dir, \"checkpoint.pt\"))\n","      model.load_state_dict(model_state)\n","      optimizer.load_state_dict(optimizer_state)\n","\n","  #data_dir = os.path.abspath(\"./data\")\n","  trainset, testset = load_data()\n","\n","  test_abs = int(len(trainset) * 0.8)\n","  train_subset, val_subset = random_split(trainset, [test_abs, len(trainset) - test_abs])\n","\n","  trainloader = torch.utils.data.DataLoader(\n","      train_subset,\n","      batch_size=int(config[\"batch_size\"]),\n","      shuffle=True,\n","      num_workers=8)\n","  valloader = torch.utils.data.DataLoader(\n","      val_subset,\n","      batch_size=int(config[\"batch_size\"]),\n","      shuffle=True,\n","      num_workers=8)\n","\n","  for epoch in range(2):  # loop over the dataset multiple times\n","      #model.train()\n","      running_loss = 0.0\n","      epoch_steps = 0\n","      for i, data in enumerate(trainloader, 0):\n","          #print('Batch train',i)\n","          # get the inputs; data is a list of [inputs, labels]\n","          inputs, labels = data\n","          inputs, labels = inputs.to(device), labels.to(device)\n","\n","          # zero the parameter gradients\n","          optimizer.zero_grad()\n","\n","          # forward + backward + optimize\n","          outputs , _ = model(inputs)\n","\n","          loss = criterion(outputs, labels)\n","          loss.backward()\n","          optimizer.step()\n","\n","          # print statistics\n","          running_loss += loss.item()\n","          epoch_steps += 1\n","          if i % 2000 == 1999:  # print every 2000 mini-batches\n","              print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1,\n","                                              running_loss / epoch_steps))\n","              running_loss = 0.0\n","\n","      # Validation loss\n","      val_loss = 0.0\n","      val_steps = 0\n","      total = 0\n","      correct = 0\n","      for i, data in enumerate(valloader, 0):\n","          with torch.no_grad():\n","              #model.eval()\n","              #print('Batch eval',i)\n","              inputs, labels = data\n","              inputs, labels = inputs.to(device), labels.to(device)\n","              outputs , _ = model(inputs)\n","              _, predicted = torch.max(outputs.data, 1)\n","\n","              total += labels.size(0)\n","              correct += (predicted == labels).sum().item()\n","\n","              loss = criterion(outputs, labels)\n","              val_loss += loss.cpu().numpy()\n","              val_steps += 1\n","\n","      # Here we save a checkpoint. It is automatically registered with\n","      # Ray Tune and can be accessed through `session.get_checkpoint()`\n","      # API in future iterations.\n","      #print('pre save', epoch)\n","      #os.makedirs('/content/drive/MyDrive/Colab_notebooks/CEIA/VCP2/TP/Fruit_multiclass/Models/Result', exist_ok=True)\n","      torch.save((model.state_dict(), optimizer.state_dict()), '/content/drive/MyDrive/Colab_notebooks/CEIA/VPC2/TP/Fruit_multiclass/Models/Result/checkpoint.pt')\n","      checkpoint = Checkpoint.from_directory('/content/drive/MyDrive/Colab_notebooks/CEIA/VPC2/TP/Fruit_multiclass/Models/Result')\n","      session.report({\"loss\": (val_loss / val_steps), \"accuracy\": correct / total}, checkpoint=checkpoint)\n","  print(\"Finished Training\")"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"MIUjEyZo4n58","executionInfo":{"status":"ok","timestamp":1665660658802,"user_tz":180,"elapsed":624,"user":{"displayName":"Juan Pablo Alianak","userId":"15176005573402506761"}}},"outputs":[],"source":["def test_best_model(best_result):\n","    #best_trained_model = Net(best_result.config[\"l1\"], best_result.config[\"l2\"])\n","    best_trained_model = Net()\n","    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n","    best_trained_model.to(device)\n","\n","    checkpoint_path = os.path.join(best_result.checkpoint.to_directory(), \"checkpoint.pt\")\n","\n","    model_state, optimizer_state = torch.load(checkpoint_path)\n","    best_trained_model.load_state_dict(model_state)\n","\n","    trainset, testset = load_data()\n","\n","    testloader = torch.utils.data.DataLoader(\n","        testset, batch_size=4, shuffle=False, num_workers=2)\n","\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data in testloader:\n","            images, labels = data\n","            images, labels = images.to(device), labels.to(device)\n","            outputs,_ = best_trained_model(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","\n","    print(\"Best trial test set accuracy: {}\".format(correct / total))"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"dCdMc4sz45cy","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"a6547cf8-f364-4442-8eb8-1a7a1777f6e9","executionInfo":{"status":"ok","timestamp":1665664280680,"user_tz":180,"elapsed":3608590,"user":{"displayName":"Juan Pablo Alianak","userId":"15176005573402506761"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["2022-10-13 11:31:08,004\tINFO worker.py:1518 -- Started a local Ray instance.\n","2022-10-13 11:31:09,995\tWARNING function_trainable.py:620 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-10-13 12:28:56 (running for 00:57:46.63)<br>Memory usage on this node: 1.9/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.031208634376526 | Iter 1.000: -3.002778520186742<br>Resources requested: 0/2 CPUs, 0/0 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects<br>Current best trial: 890f6_00001 with loss=1.4244477252165477 and parameters={'lr': 0.0006368200672277239, 'batch_size': 32}<br>Result logdir: /root/ray_results/train_inceptionv3_2022-10-13_11-31-05<br>Number of trials: 2/2 (2 TERMINATED)<br><table>\n","<thead>\n","<tr><th>Trial name                   </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">        lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>train_inceptionv3_890f6_00000</td><td>TERMINATED</td><td>172.28.0.2:1389</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">0.0483239 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         1726.85</td><td style=\"text-align: right;\">2.63797</td><td style=\"text-align: right;\">  0.67374 </td></tr>\n","<tr><td>train_inceptionv3_890f6_00001</td><td>TERMINATED</td><td>172.28.0.2:1389</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">0.00063682</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         1734.95</td><td style=\"text-align: right;\">1.42445</td><td style=\"text-align: right;\">  0.681698</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[2m\u001b[36m(train_inceptionv3 pid=1389)\u001b[0m /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","\u001b[2m\u001b[36m(train_inceptionv3 pid=1389)\u001b[0m   cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[2m\u001b[36m(train_inceptionv3 pid=1389)\u001b[0m pre save 0\n","Result for train_inceptionv3_890f6_00000:\n","  accuracy: 0.5649867374005305\n","  date: 2022-10-13_11-45-42\n","  done: false\n","  experiment_id: d6515df668c040b596ad40b43bde97ac\n","  hostname: c2b40ee7fc0c\n","  iterations_since_restore: 1\n","  loss: 4.21274596452713\n","  node_ip: 172.28.0.2\n","  pid: 1389\n","  should_checkpoint: true\n","  time_since_restore: 867.909773349762\n","  time_this_iter_s: 867.909773349762\n","  time_total_s: 867.909773349762\n","  timestamp: 1665661542\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: 890f6_00000\n","  warmup_time: 0.004838228225708008\n","  \n","\u001b[2m\u001b[36m(train_inceptionv3 pid=1389)\u001b[0m pre save 1\n","Result for train_inceptionv3_890f6_00000:\n","  accuracy: 0.6737400530503979\n","  date: 2022-10-13_12-00-01\n","  done: false\n","  experiment_id: d6515df668c040b596ad40b43bde97ac\n","  hostname: c2b40ee7fc0c\n","  iterations_since_restore: 2\n","  loss: 2.6379695435365043\n","  node_ip: 172.28.0.2\n","  pid: 1389\n","  should_checkpoint: true\n","  time_since_restore: 1726.8505330085754\n","  time_this_iter_s: 858.9407596588135\n","  time_total_s: 1726.8505330085754\n","  timestamp: 1665662401\n","  timesteps_since_restore: 0\n","  training_iteration: 2\n","  trial_id: 890f6_00000\n","  warmup_time: 0.004838228225708008\n","  \n","Result for train_inceptionv3_890f6_00000:\n","  accuracy: 0.6737400530503979\n","  date: 2022-10-13_12-00-01\n","  done: true\n","  experiment_id: d6515df668c040b596ad40b43bde97ac\n","  experiment_tag: 0_batch_size=32,lr=0.0483\n","  hostname: c2b40ee7fc0c\n","  iterations_since_restore: 2\n","  loss: 2.6379695435365043\n","  node_ip: 172.28.0.2\n","  pid: 1389\n","  should_checkpoint: true\n","  time_since_restore: 1726.8505330085754\n","  time_this_iter_s: 858.9407596588135\n","  time_total_s: 1726.8505330085754\n","  timestamp: 1665662401\n","  timesteps_since_restore: 0\n","  training_iteration: 2\n","  trial_id: 890f6_00000\n","  warmup_time: 0.004838228225708008\n","  \n","\u001b[2m\u001b[36m(train_inceptionv3 pid=1389)\u001b[0m Finished Training\n","\u001b[2m\u001b[36m(train_inceptionv3 pid=1389)\u001b[0m pre save 0\n","Result for train_inceptionv3_890f6_00001:\n","  accuracy: 0.5305039787798409\n","  date: 2022-10-13_12-14-26\n","  done: false\n","  experiment_id: d6515df668c040b596ad40b43bde97ac\n","  hostname: c2b40ee7fc0c\n","  iterations_since_restore: 1\n","  loss: 1.7928110758463542\n","  node_ip: 172.28.0.2\n","  pid: 1389\n","  should_checkpoint: true\n","  time_since_restore: 864.9844479560852\n","  time_this_iter_s: 864.9844479560852\n","  time_total_s: 864.9844479560852\n","  timestamp: 1665663266\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: 890f6_00001\n","  warmup_time: 0.004838228225708008\n","  \n","\u001b[2m\u001b[36m(train_inceptionv3 pid=1389)\u001b[0m pre save 1\n","Result for train_inceptionv3_890f6_00001:\n","  accuracy: 0.6816976127320955\n","  date: 2022-10-13_12-28-56\n","  done: false\n","  experiment_id: d6515df668c040b596ad40b43bde97ac\n","  hostname: c2b40ee7fc0c\n","  iterations_since_restore: 2\n","  loss: 1.4244477252165477\n","  node_ip: 172.28.0.2\n","  pid: 1389\n","  should_checkpoint: true\n","  time_since_restore: 1734.9484295845032\n","  time_this_iter_s: 869.963981628418\n","  time_total_s: 1734.9484295845032\n","  timestamp: 1665664136\n","  timesteps_since_restore: 0\n","  training_iteration: 2\n","  trial_id: 890f6_00001\n","  warmup_time: 0.004838228225708008\n","  \n","\u001b[2m\u001b[36m(train_inceptionv3 pid=1389)\u001b[0m Finished Training\n","Result for train_inceptionv3_890f6_00001:\n","  accuracy: 0.6816976127320955\n","  date: 2022-10-13_12-28-56\n","  done: true\n","  experiment_id: d6515df668c040b596ad40b43bde97ac\n","  experiment_tag: 1_batch_size=32,lr=0.0006\n","  hostname: c2b40ee7fc0c\n","  iterations_since_restore: 2\n","  loss: 1.4244477252165477\n","  node_ip: 172.28.0.2\n","  pid: 1389\n","  should_checkpoint: true\n","  time_since_restore: 1734.9484295845032\n","  time_this_iter_s: 869.963981628418\n","  time_total_s: 1734.9484295845032\n","  timestamp: 1665664136\n","  timesteps_since_restore: 0\n","  training_iteration: 2\n","  trial_id: 890f6_00001\n","  warmup_time: 0.004838228225708008\n","  \n"]},{"output_type":"stream","name":"stderr","text":["2022-10-13 12:28:57,012\tINFO tune.py:759 -- Total run time: 3467.02 seconds (3466.62 seconds for the tuning loop).\n"]},{"output_type":"stream","name":"stdout","text":["Best trial config: {'lr': 0.0006368200672277239, 'batch_size': 32}\n","Best trial final validation loss: 1.4244477252165477\n","Best trial final validation accuracy: 0.6816976127320955\n","Best trial test set accuracy: 0.5107913669064749\n"]}],"source":["num_samples=2\n","max_num_epochs=10\n","gpus_per_trial=0\n","\n","config = {\n","    \"lr\": tune.loguniform(1e-4, 1e-1),\n","    \"batch_size\": tune.choice([16, 32, 64])\n","}\n","\n","scheduler = ASHAScheduler(\n","    max_t=max_num_epochs,\n","    grace_period=1,\n","    reduction_factor=2\n","    )\n","\n","reporter = CLIReporter(\n","    # parameter_columns=[\"l1\", \"l2\", \"lr\", \"batch_size\"],\n","    metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n","   \n","tuner = tune.Tuner(\n","    tune.with_resources(\n","        tune.with_parameters(train_inceptionv3),\n","        resources={\"cpu\": 2, \"gpu\": gpus_per_trial}\n","    ),\n","    tune_config=tune.TuneConfig(\n","        metric=\"loss\",\n","        mode=\"min\",\n","        scheduler=scheduler,\n","        num_samples=num_samples,\n","            \n","    ),\n","    param_space=config\n",")\n","\n","results = tuner.fit()\n","   \n","best_result = results.get_best_result(\"loss\", \"min\")\n","\n","print(\"Best trial config: {}\".format(best_result.config))\n","print(\"Best trial final validation loss: {}\".format(\n","    best_result.metrics[\"loss\"]))\n","print(\"Best trial final validation accuracy: {}\".format(\n","    best_result.metrics[\"accuracy\"]))\n","\n","test_best_model(best_result)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[],"authorship_tag":"ABX9TyOKRkthxsdjQ01PZ8dUzogu"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}